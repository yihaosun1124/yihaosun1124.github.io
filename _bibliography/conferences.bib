@inproceedings{mobile,
  author    = {Yihao Sun* and
               Jiaji Zhang* and
               Chengxing Jia and
               Haoxin Lin and
               Junyin Ye and
               Yang Yu},
  title     = {Model-Bellman inconsistency for model-based offline reinforcement learning},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning (ICML'23)},
  address   = {Honolulu, HA},
  year      = {2023},
  abbr      = {ICML},
  url       = {https://proceedings.mlr.press/v202/sun23q.html},
  code      = {https://github.com/yihaosun1124/mobile},
  selected  = {true},
}

@inproceedings{mppve,
  author       = {Haoxin Lin* and
                  Yihao Sun* and
                  Jiaji Zhang and
                  Yang Yu},
  title        = {Model-based reinforcement learning with multi-step plan value estimation},
  booktitle = {Proceedings of the 26th European Conference on Artificial Intelligence (ECAI'23)},
  address   = {Krak√≥w, Poland},
  year      = {2023},
  abbr      = {ECAI},
  url       = {https://doi.org/10.48550/arXiv.2209.05530},
  code      = {https://github.com/HxLyn3/MPPVE},
  selected  = {false},
}

@inproceedings{diaster,
  author       = {Haoxin Lin and
                  Hongqiu Wu and
                  Jiaji Zhang and
                  Yihao Sun and
                  Junyin Ye and
                  Yang Yu},
  title        = {Episodic return decomposition by difference of implicitly assigned sub-trajectory reward},
  booktitle = {Proceedings of the 38th Annual AAAI Conference on Artificial Intelligence (AAAI'24)},
  address   = {Vancouver, Canada},
  year      = {2024},
  abbr      = {AAAI},
  url       = {https://arxiv.org/abs/2312.10642},
  code      = {https://github.com/HxLyn3/Diaster},
  selected  = {false},
}

@inproceedings{ftb,
  author       = {Zhilong Zhang* and
                  Yihao Sun* and
                  Junyin Ye and
                  Tianshuo Liu and
                  Jiaji Zhang and
                  Yang Yu},
  title        = {Flow to better: Offline preference-based reinforcement learning via preferred trajectory generation},
  booktitle = {Proceedings of the 12th International Conference on Learning Representations (ICLR'24)},
  address   = {Vienna, Austria},
  year      = {2024},
  abbr      = {ICLR},
  url       = {https://openreview.net/forum?id=EG68RSznLT&noteId=u4rDNGCHON},
  code      = {https://github.com/Zzl35/flow-to-better},
  selected  = {true},
}

@inproceedings{pcm,
  author       = {Ruifeng Chen* and
                  Xiong-Hui Chen* and
                  Yihao Sun and
                  Siyuan Xiao and
                  Minhui Li and
                  Yang Yu},
  title        = {Policy-conditioned environment models are more generalizable},
  booktitle = {Proceedings of the 41th International Conference on Machine Learning (ICML'24)},
  address   = {Vienna, Austria},
  year      = {2024},
  abbr      = {ICML},
  url       = {https://openreview.net/pdf?id=g9mYBdooPA},
  code      = {https://github.com/LAMDA-RL/policy-conditioned-model},
  selected  = {false},
}

@inproceedings{optail,
  author       = {Tian Xu and
                  Zhilong Zhang and
                  Ruishuo Chen and
                  Yihao Sun and
                  Yang Yu},
  title        = {Provably and practically efficient adversarial imitation learning with general function approximation},
  booktitle = {Advances in Neural Information Processing Systems 38 (NeurIPS'24)},
  address   = {Vancouver, Canada},
  year      = {2024},
  abbr      = {NeurIPS},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2024/file/79b90b4c2ee23cc35fdd8de2969dc4e8-Paper-Conference.pdf},
  code      = {https://github.com/Zzl35/OPT-AIL},
  selected  = {false},
}

@inproceedings{admpo,
  author       = {Haoxin Lin and
                  Yu-Yan Xu and
                  Yihao Sun and
                  Zhilong Zhang and
                  Yi-Chen Li and
                  Chengxing Jia and
                  Junyin Ye and
                  Jiaji Zhang and
                  Yang Yu},
  title        = {Any-step dynamics model improves future predictions for online and offline reinforcement learning},
  booktitle = {Proceedings of the 13th International Conference on Learning Representations (ICLR'25)},
  address   = {Singapore},
  year      = {2025},
  abbr      = {ICLR},
  url       = {https://openreview.net/forum?id=JZCxlrwjZ8},
  code      = {https://github.com/HxLyn3/ADMPO},
  selected  = {false},
}