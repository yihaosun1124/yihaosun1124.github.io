@inproceedings{mobile,
  author    = {Yihao Sun* and
               Jiaji Zhang* and
               Chengxing Jia and
               Haoxin Lin and
               Junyin Ye and
               Yang Yu},
  title     = {Model-Bellman inconsistency for model-based offline reinforcement learning},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning (ICML'23)},
  address   = {Honolulu, HA},
  year      = {2023},
  abbr      = {ICML},
  url       = {https://proceedings.mlr.press/v202/sun23q.html},
  code      = {https://github.com/yihaosun1124/mobile},
  selected  = {true},
}

@inproceedings{mppve,
  author       = {Haoxin Lin* and
                  Yihao Sun* and
                  Jiaji Zhang and
                  Yang Yu},
  title        = {Model-based reinforcement learning with multi-step plan value estimation},
  booktitle = {Proceedings of the 26th European Conference on Artificial Intelligence (ECAI'23)},
  address   = {Krak√≥w, Poland},
  year      = {2023},
  abbr      = {ECAI},
  url       = {https://doi.org/10.48550/arXiv.2209.05530},
  code      = {https://github.com/HxLyn3/MPPVE},
  selected  = {false},
}

@inproceedings{diaster,
  author       = {Haoxin Lin and
                  Hongqiu Wu and
                  Jiaji Zhang and
                  Yihao Sun and
                  Junyin Ye and
                  Yang Yu},
  title        = {Episodic return decomposition by difference of implicitly assigned sub-trajectory reward},
  booktitle = {Proceedings of the 38th Annual AAAI Conference on Artificial Intelligence (AAAI'24)},
  address   = {Vancouver, Canada},
  year      = {2024},
  abbr      = {AAAI},
  url       = {https://arxiv.org/abs/2312.10642},
  code      = {https://github.com/HxLyn3/Diaster},
  selected  = {false},
}

@inproceedings{ftb,
  author       = {Zhilong Zhang* and
                  Yihao Sun* and
                  Junyin Ye and
                  Tianshuo Liu and
                  Jiaji Zhang and
                  Yang Yu},
  title        = {Flow to better: Offline preference-based reinforcement learning via preferred trajectory generation},
  booktitle = {Proceedings of the 12th International Conference on Learning Representations (ICLR'24)},
  address   = {Vienna, Austria},
  year      = {2024},
  abbr      = {ICLR},
  url       = {https://openreview.net/forum?id=EG68RSznLT&noteId=u4rDNGCHON},
  code      = {https://github.com/Zzl35/flow-to-better},
  selected  = {true},
}